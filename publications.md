---
layout: page
title: Research and Publications
subtitle: As a sophomore...there's still long way to go.
---

### Academic Interests
**Artificial Intelligence**: My journey into the realm of AI, particularly Deep Learning and Natural Language Processing, has been fueled by a fascination with Large Language Models (LLMs) like GPT-4. The recent advancements in these models, especially their capabilities in tasks like machine translation and logical reasoning, have deepened my interest. I am intrigued by the concept of prompt engineering and am constantly exploring ways to enhance the performance of LLMs.

**Linguistics**: My major in Linguistics has naturally led me to an interest in Computational Linguistics (CL), an exciting intersection between computer science and linguistics. This field allows me to apply my understanding of language structures in the digital domain. I am also captivated by formal semantics, psycholinguistics, and neurolinguistics. These areas offer profound insights into how language interacts with our cognitive and neural processes.

My academic journey so far has been marked by significant experiences, such as participating in an undergraduate research program under Prof. Hu Hai, focusing on the performance of Natural Language Inference (NLI) models on Chinese and multilingual texts. This experience highlighted the challenges in language model accuracy, especially with complex linguistic elements like Chinese idioms. It has also taught me the importance of collaboration between linguists and experts in other domains for future advancements in this field.

As I continue my academic journey, I am eager to delve deeper into computational linguistics and NLP, understanding their limitations and potential, and contributing to the development of technologies that enable seamless communication between humans and machines.



### Publications
Not available now.

Please be patient! I'm trying my best to do something. Get back in a few months and check again.

### Research in Progress
**Benchmarking LLMs with Chinese Xiehouyu**

Xiehouyu(歇后语) is a unique form of expression in Chinese, characterized by its brevity, wit, and vivid imagery. It consists of two parts: the first part acts as a 'lead-in,' similar to a riddle's setup, while the second part serves as the 'backing,' akin to the riddle's answer, fitting naturally and appropriately. In practical use, people often only say the first half and omit the second, allowing the listener to understand and guess its true meaning, hence the name xiehouyu.

We aim to test the linguistic capabilities of large language models in various aspects by designing a database that includes xiehouyu.


### Other Works
**Undergraduate Research Program at SJTU: Performance of NLI Models on parsing Chinese Idioms** 

Instructed by professor Hai Hu, we studied pre-trained language models and the figurative meaning of language. We compiled test data containing Chinese idioms and conducted tests on three different RoBERTa-based models. We evaluated the performance of the models and examined the relationship between model performance and linguistic phenomena.

We also conducted a series of tests on existing advanced LLMs (OpenAI GPT family and other open-source models) to answer questions including, but not limited to: Can LLMs understand idioms and figurative language? In which categories of figurative language do these models perform better or worse? What factors might influence the performance of these models?







