---
layout: page
title: Research and Publications
subtitle: As a sophomore...there's still long way to go.
---

### Academic Interests
**Artificial Intelligence**: My journey into the realm of AI, particularly Deep Learning and Natural Language Processing, has been fueled by a fascination with Large Language Models (LLMs) like GPT-4. The recent advancements in these models, especially their capabilities in tasks like machine translation and logical reasoning, have deepened my interest. I am intrigued by the concept of prompt engineering and am constantly exploring ways to enhance the performance of LLMs.

**Linguistics**: My major in Linguistics has naturally led me to an interest in Computational Linguistics (CL), an exciting intersection between computer science and linguistics. This field allows me to apply my understanding of language structures in the digital domain. I am also captivated by formal semantics, psycholinguistics, and neurolinguistics. These areas offer profound insights into how language interacts with our cognitive and neural processes.

My academic journey so far has been marked by significant experiences, such as participating in an undergraduate research program under Prof. Hu Hai, focusing on the performance of Natural Language Inference (NLI) models on Chinese and multilingual texts. This experience highlighted the challenges in language model accuracy, especially with complex linguistic elements like Chinese idioms. It has also taught me the importance of collaboration between linguists and experts in other domains for future advancements in this field.

As I continue my academic journey, I am eager to delve deeper into computational linguistics and NLP, understanding their limitations and potential, and contributing to the development of technologies that enable seamless communication between humans and machines.



### Publications
Not available now.

Please be patient! I'm trying my best to do something. Get back in a few months and check again.

### Research in Progress
**LLM's Comprehension of Idioms and Figurative meaning**

Inspired by the Idiom NLI project, we will conduct a series of tests on existing Advanced LLMs to answer questions including, but not limited to: Can LLMs understand idioms and figurative language? In which categories of figurative language do these models perform better or worse? What factors might influence the performance of these models?



### Other Works
**Undergraduate Research: Performance of NLI Models on parsing Chinese Idioms** 

Instructed by professor Hai Hu, we studied pre-trained language models and the figurative meaning of language. We compiled test data containing Chinese idioms and conducted tests on three different RoBERTa-based models. We evaluated the performance of the models and examined the relationship between model performance and linguistic phenomena.



**PRP Program: Financial AI algorithms and fairness**

Instructed by professor Chunxiao Li, we reviewed literature on feature engineering and model interpretability, applied advanced classification algorithms such as LightGBM and XGBoost on the Home Credit dataset, and assessed whether existing AI models for credit exhibit discrimination in various aspects.


